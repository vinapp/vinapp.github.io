<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Multi class image generation using Stable Diffusion | Vinod Appajanna</title>
    <meta name="author" content="Vinod  Appajanna" />
    <meta name="description" content="Voice based Multi class image generation using Stable Diffusion" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light" />

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://vinapp.github.io/blog/2022/multi-class-image-generation-stablediffusion/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="//">Vinod Appajanna</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blogs<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Multi class image generation using Stable Diffusion</h1>
    <p class="post-meta">October 1, 2022</p>
    <p class="post-tags">
      <a href="//blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
      &nbsp; &middot; &nbsp;
        <a href="//blog/tag/ai">
          <i class="fas fa-hashtag fa-sm"></i> ai</a> &nbsp;
          <a href="//blog/tag/ml">
          <i class="fas fa-hashtag fa-sm"></i> ml</a> &nbsp;
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#problem-statement">Problem Statement</a></li>
<li class="toc-entry toc-h1"><a href="#task">Task</a></li>
<li class="toc-entry toc-h1"><a href="#why-is-it-interesting-">Why is it interesting ?</a></li>
<li class="toc-entry toc-h1"><a href="#data">Data</a></li>
<li class="toc-entry toc-h1"><a href="#methods-to-experiment">Methods to experiment</a></li>
<li class="toc-entry toc-h1"><a href="#jupyter-notebook---tryout-out">Jupyter Notebook - Tryout out</a></li>
<li class="toc-entry toc-h1"><a href="#result-evaluation">Result Evaluation</a></li>
<li class="toc-entry toc-h1"><a href="#references">References</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <h1 id="problem-statement">Problem Statement</h1>

<p>We have seen the generative models like Diffusion Model for some time. With the release of Stable Diffusion’s (released recently as early as August 2022) the code and the model weights have been released publicly allowing users to have more control over the topic picture and then controlling the diffusion model using text-based inputs, we can do a transfer learning for a subject &amp; an identifier with just few images. Also, we see that there are only few articles on these and especially only covering a single class transfer learning. So, taking advantage of this we see an option of training (our own set of images) with different classes (with our own identifiers) and clubbing multiple classes. So with this we can issue a single sentence/text which covers all the classes/identifiers and generate images based our custom image set. Also, extending text-to-image to voice-to-text-to-image helps.</p>

<h1 id="task">Task</h1>

<ul>
  <li>For our own set of images train with the pre-trained model with multiple classes/subjects and the identifier’s</li>
  <li>Add a support to speech to text option on top of text to image option</li>
  <li>Find the group of classes/subject that we want to train and test the same with different text’s (sentences). Testing could be manual or based on the labelled data.</li>
</ul>

<h1 id="why-is-it-interesting-">Why is it interesting ?</h1>

<p>Interesting because imagination becomes real in the image. One of the powerful use case would be in slide preparation or storyboard creation wherein we can generate images on our own set of images (grouped into different class) that are trained via transfer learning. This would save time and also have multiple imaginative image generation options. Also, here we have some control over the image generation since its operating on our own set of images.</p>

<p>Also, although there are articles/blogs on stable diffusion (past 2 months) on training individual class (CAT/DOG et) but we haven’t seen any articles (so far) on how we can use set/group of images and how we can iteratively create multiple classes one of top of each other along with publicly available dream booth diffusion model data. So, this could be a nice candidate for publishing a blog that would be very useful to people.</p>

<p>Eg:</p>

<p><strong>photo of &lt;custom-identifier&gt; &lt;class-name&gt;</strong></p>

<ul>
  <li>photo of &lt;xyz&gt; &lt;temple&gt; —&gt; Single class</li>
  <li>photo of &lt;kar&gt; &lt;forest&gt; —&gt; Single class</li>
  <li>photo of &lt;xyz&gt; &lt;temple&gt; in &lt;kar&gt; &lt;forest&gt; and sunlight —&gt; Mixing multiple custom classes</li>
</ul>

<p>This one especially touches all/most of ML aspects like deep learning, un-supervised, synthesized data, labelled data, text summarization, voice to text, text to image etc. This one will serve as a nice learning experience for all of us.</p>

<p>Example Usecase: Think of having a plugin (to powerpoint/google slides) that can integrate custom generative model to generate our own choice of images and this would be very powerful… For eg: Every week if we need to publish some articles (say related to temples) and I need some creative images and it’s very difficult to get the images of our own choice and that too for say 100’s of articles. So in that case this is very useful and we don’t have bother out <a href="https://huggingface.co/CompVis/stable-diffusion">licensing</a> issues as well unless it’s not misused.</p>

<h1 id="data">Data</h1>
<ul>
  <li>To start with we require only few sets of images for transfer learning</li>
  <li>Verifying the result is a bit challenging but we could leverage the labelled data.</li>
</ul>

<h1 id="methods-to-experiment">Methods to experiment</h1>
<ul>
  <li>
    <p>For transfer learning we an use different sets of custom images for different classes. In my case I have use images of Temple and few images for background. The new class we train will be on top of the previous classes. At the end we give the instruction in the form of speech or text (that covers all the classes and identifiers) to generate the synthesized images.</p>

    <p>Below is the example images that is generated from stable diffusion model:
 <img width="944" alt="image" src="https://github.com/vinapp/vinapp.github.io/assets/8567548/00fff27c-2174-4b30-a474-7eecfe9c9b89" /></p>
  </li>
</ul>

<h1 id="jupyter-notebook---tryout-out">Jupyter Notebook - Tryout out</h1>
<p>Download this Jupyter Notebook <a href="https://vinapp.github.io/assets/ipynb/multi_class_image_generation_using_dreambooth_stable_diffusion.ipynb"> multi_class_image_generation_using_dreambooth_stable_diffusion.ipynb</a> for training your own set of images &amp; for the inference.</p>

<p><strong>Steps</strong></p>

<ul>
  <li>Train &amp; Save Model
    <hr />

    <p><img width="944" alt="image" src="https://github.com/vinapp/vinapp.github.io/assets/8567548/21e11ac2-5363-42c9-97d8-744422234fe0" /></p>
    <hr />

    <p><img width="935" alt="image" src="https://github.com/vinapp/vinapp.github.io/assets/8567548/a8e77ec7-bbc9-42c8-930c-14047492ea7e" /></p>
    <hr />

    <p><img width="930" alt="image" src="https://github.com/vinapp/vinapp.github.io/assets/8567548/4ba43e09-03df-4e4c-974f-636e4b016a47" /></p>
  </li>
  <li>Image Generation
    <hr />

    <p><img width="940" alt="image" src="https://github.com/vinapp/vinapp.github.io/assets/8567548/1f88f34e-23e2-4c39-84a1-9a4482a0f6ca" /></p>
    <hr />

    <p><img width="783" alt="image" src="https://github.com/vinapp/vinapp.github.io/assets/8567548/7860471d-1e35-445a-b08b-b8d8200ed143" /></p>
    <hr />
  </li>
</ul>

<h1 id="result-evaluation">Result Evaluation</h1>

<ul>
  <li>Fidelity: the quality of the generated samples. Measures how realistic the images are. You can think of it as how different each fake sample is from its nearest real sample.</li>
  <li>Diversity: the variety of the generated samples. Measures how well the generated images cover the whole diversity or variety of the real distribution.</li>
</ul>

<p>We can use the labelled trained images to match against the generated images and for this we need more images to train the labelled data.</p>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Stable\_Diffusion">Stable Diffusion</a></li>
  <li><a href="https://arxiv.org/pdf/2208.12242.pdf">Dream booth Diffusion</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Diffusion_model">Diffusion Model</a></li>
  <li>
    <p><a href="https://huggingface.co/CompVis/stable-diffusion">Stable Diffusion Model</a></p>

    <p><strong>Related Work/Articles</strong></p>
    <ul>
      <li><a href="https://techpp.com/2022/10/10/how-to-train-stable-diffusion-ai-dreambooth/">Train Stable Diffusion Model</a></li>
      <li><a href="https://bytexd.com/how-to-use-dreambooth-to-fine-tune-stable-diffusion-colab/">Fine Tune Stable Diffusion Model</a></li>
    </ul>
  </li>
</ul>

    </div>
  </article></div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        &copy; Copyright 2023 Vinod  Appajanna. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
